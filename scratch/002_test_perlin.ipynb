{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from dataclasses import asdict, dataclass, field\n",
    "import vsketch\n",
    "import shapely.geometry as sg\n",
    "from shapely.geometry import box, MultiLineString, Point, MultiPoint, Polygon, MultiPolygon, LineString\n",
    "import shapely.affinity as sa\n",
    "import shapely.ops as so\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import vpype_cli\n",
    "from typing import List, Generic\n",
    "from genpen import genpen as gp, utils as utils\n",
    "from scipy import stats as ss\n",
    "import geopandas\n",
    "from shapely.errors import TopologicalError\n",
    "import functools\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def occlude(top, bottom, distance=1e-6):\n",
    "    try:\n",
    "        return bottom.difference(top)\n",
    "    except TopologicalError:\n",
    "        return bottom.buffer(distance).difference(top.buffer(distance))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class ParticleCluster(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        pos,\n",
    "        perlin_grid,\n",
    "    ):\n",
    "        self.pos = Point(pos)\n",
    "        self.pg = perlin_grid\n",
    "        self.particles = []\n",
    "        \n",
    "    def gen_start_pts_gaussian(\n",
    "            self,\n",
    "            n_particles=10,\n",
    "            xloc=0.,\n",
    "            xscale=1.,\n",
    "            yloc=0.,\n",
    "            yscale=1.,\n",
    "        ):\n",
    "        xs = self.pos.x + ss.norm(loc=xloc, scale=xscale).rvs(n_particles)\n",
    "        ys = self.pos.y + ss.norm(loc=yloc, scale=yscale).rvs(n_particles)\n",
    "        self.start_pts = [Point((x,y)) for x,y in zip(xs, ys)]\n",
    "        \n",
    "    def init_particles(self, start_bounds=None):\n",
    "        for pt in self.start_pts:\n",
    "            p = gp.Particle(pos=pt, grid=self.pg)\n",
    "            if start_bounds == None:\n",
    "                self.particles.append(p)\n",
    "            elif start_area.contains(p.pos):\n",
    "                self.particles.append(p)\n",
    "                \n",
    "    @functools.singledispatchmethod           \n",
    "    def step(self, n_steps):\n",
    "        for p,n in zip(self.particles, n_steps):\n",
    "            for i in range(n):\n",
    "                p.step()\n",
    "    \n",
    "    @step.register\n",
    "    def _(self, n_steps: int):\n",
    "        n_steps = [n_steps] * len(self.particles)\n",
    "        for p,n in zip(self.particles, n_steps):\n",
    "                for i in range(n):\n",
    "                    p.step()\n",
    "                    \n",
    "    @property\n",
    "    def lines(self):\n",
    "        return MultiLineString([p.line for p in self.particles])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ScaleTransPrms(gp.DataClassBase):\n",
    "    \n",
    "    n_iters: int = 100\n",
    "    d_buffer: float = -0.25\n",
    "    d_translate_factor: float = 0.9\n",
    "    d_translate: float = None\n",
    "    angles: float = 0.\n",
    "    d_translates: list = field(default=None, init=False)\n",
    "    def __post_init__(self):\n",
    "        self.d_buffers = np.array([self.d_buffer] * self.n_iters)\n",
    "        \n",
    "        if self.d_translates == None:\n",
    "            if self.d_translate != None:\n",
    "                self.d_translates =  np.array([self.d_translate] * self.n_iters)\n",
    "            else:\n",
    "                self.d_translates = self.d_buffers * self.d_translate_factor\n",
    "    \n",
    "    @property\n",
    "    def prms(self):\n",
    "        varnames = ['d_buffers', 'd_translates', 'angles']\n",
    "        return {var: getattr(self, var) for var in varnames}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def individual_difference(multipolygon0, multipolygon1, dist=1e-6):\n",
    "    diffs = []\n",
    "    for p0, p1 in itertools.product(multipolygon0, multipolygon1):\n",
    "        if p0.overlaps(p1):\n",
    "            try:\n",
    "                diff = p0.difference(p1)\n",
    "            except TopologicalError:\n",
    "                diff = p0.buffer(dist).difference(p1.buffer(dist))\n",
    "            diffs.append(diff)\n",
    "    return diffs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## try 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 11. # inches\n",
    "page_y_inches: float = 8.5 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':3,\n",
    "    'ystep':3,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0073,\n",
    "    'noiseSeed':6\n",
    "}\n",
    "\n",
    "particle_init_grid_params = {\n",
    "    'xstep':16,\n",
    "    'ystep':16,\n",
    "}\n",
    "\n",
    "buffer_style = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "pg = gp.PerlinGrid(drawbox, **perlin_grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "start_area = sa.scale(drawbox.centroid.buffer(brad*0.45), xfact=1.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "start_area = drawbox.buffer(-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "xcs, ycs = gp.overlay_grid(start_area, xstep=19, ystep=15)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=20, xscale=4, yscale=4)\n",
    "    pc.init_particles()\n",
    "    n_steps = np.random.randint(low=10, high=50, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.3, high=1.3) + np.random.uniform(low=0., high=0.7, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "\n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.45, high=-0.25), \n",
    "        angles=-90,\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.03, 0.03, size=stp.d_buffers.shape)\n",
    "    P.fill_scale_trans(**stp.prms)\n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except :\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ifills = []\n",
    "for p in gpolys:\n",
    "    try:\n",
    "        ifills.append(p.intersection_fill)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "splits = utils.random_split(ifills, n_layers=5)\n",
    "layers = [utils.merge_LineStrings(split) for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0083_perlin_flow_erode_frays_occlude.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'linesimplify --tolerance 0.01mm linemerge --tolerance 0.1mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 11. # inches\n",
    "page_y_inches: float = 8.5 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':1,\n",
    "    'ystep':1,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0073,\n",
    "    'noiseSeed':8\n",
    "}\n",
    "buffer_style = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "pg = gp.PerlinGrid(drawbox, **perlin_grid_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "start_area = drawbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "xcs, ycs = gp.overlay_grid(start_area, xstep=15, ystep=15)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=30, xscale=7, yscale=7)\n",
    "    pc.init_particles(start_bounds=drawbox)\n",
    "    n_steps = np.random.randint(low=10, high=90, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.3, high=1.3) + np.random.uniform(low=0., high=0.7, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "\n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.4, high=-0.2),\n",
    "        d_translate_factor=0.7,\n",
    "        angles=-240,\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.03, 0.03, size=stp.d_buffers.shape)\n",
    "    P.fill_scale_trans(**stp.prms)\n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except:\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ifills = []\n",
    "for p in gpolys:\n",
    "    ifills.append(p.intersection_fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "splits = utils.random_split(ifills, n_layers=4)\n",
    "layers = [utils.merge_LineStrings(split) for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0084_perlin_flow_erode_frays_occlude.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'linesimplify --tolerance 0.05mm linemerge --tolerance 0.1mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## try 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 6 # inches\n",
    "page_y_inches: float = 6 # inches\n",
    "border:float = 20.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':1,\n",
    "    'ystep':1,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0063,\n",
    "    'noiseSeed':8\n",
    "}\n",
    "buffer_style = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "pg = gp.PerlinGrid(drawbox, **perlin_grid_params)\n",
    "start_area = drawbox\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=45, ystep=45)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=30, xscale=6, yscale=6)\n",
    "    pc.init_particles(start_bounds=drawbox)\n",
    "    n_steps = np.random.randint(low=80, high=190, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.3, high=1.3) + np.random.uniform(low=0., high=0.7, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "    \n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.4, high=-0.2),\n",
    "        d_translate_factor=0.7,\n",
    "        angles=-240,\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.03, 0.03, size=stp.d_buffers.shape)\n",
    "    P.fill0 = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "    \n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.4, high=-0.2),\n",
    "        d_translate_factor=0.7,\n",
    "        angles=120,\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.03, 0.03, size=stp.d_buffers.shape)\n",
    "    P.fill1 = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except:\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ifills0 = []\n",
    "ifills1 = []\n",
    "for p in gpolys:\n",
    "    ifills0.append(p.fill0.intersection(p.p.buffer(1e-6)))\n",
    "    ifills1.append(p.fill1.intersection(p.p.buffer(1e-6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append(gp.merge_LineStrings(ifills0))\n",
    "layers.append(gp.merge_LineStrings(ifills1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0085_perlin_flow_erode_frays_color_mix.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'linesimplify --tolerance 0.2mm linemerge --tolerance 0.2mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## try 4 for fabiano black black"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "\n",
    "border:float = 25.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':1,\n",
    "    'ystep':1,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0063,\n",
    "    'noiseSeed':8\n",
    "}\n",
    "buffer_style = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = 200\n",
    "py = 200\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "start_area = drawbox.centroid.buffer(brad/2)\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=11, ystep=11)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=35, xscale=4, yscale=4)\n",
    "    pc.init_particles(start_bounds=drawbox)\n",
    "    n_steps = np.random.randint(low=10, high=60, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.3, high=1.7) + np.random.uniform(low=0., high=0.7, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "    \n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.45, high=-0.25),\n",
    "        d_translate_factor=0.7,\n",
    "        angles=-240,\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.06, 0.06, size=stp.d_buffers.shape)\n",
    "    P.fill0 = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "    \n",
    "    \n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except:\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ifills0 = []\n",
    "for p in gpolys:\n",
    "    ifills0.append(p.fill0.intersection(p.p.buffer(1e-6)))\n",
    "\n",
    "ifills0 = [l for l in ifills0 if l.length > 1e-1]\n",
    "\n",
    "layers = []\n",
    "layers.append(gp.merge_LineStrings(ifills0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0086_perlin_flow_erode_frays_color_mix.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'linesimplify --tolerance 0.2mm linemerge --tolerance 0.2mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "true"
   },
   "source": [
    "## try 5 two color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 8.5 # inches\n",
    "page_y_inches: float = 11 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':1,\n",
    "    'ystep':1,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0063,\n",
    "    'noiseSeed':8\n",
    "}\n",
    "buffer_style = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "start_area = drawbox.centroid.buffer(brad*0.47)\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=15, ystep=15)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=30, xscale=7, yscale=7)\n",
    "    pc.init_particles(start_bounds=drawbox)\n",
    "    n_steps = np.random.randint(low=10, high=100, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.3, high=2.7) + np.random.uniform(low=0., high=0.7, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "    \n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.5, high=-0.25),\n",
    "        d_translate_factor=0.7,\n",
    "        angles=np.radians(-60),\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.06, 0.06, size=stp.d_buffers.shape)\n",
    "    P.fill0 = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "    \n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.5, high=-0.25),\n",
    "        d_translate_factor=0.7,\n",
    "        angles=np.radians(-120),\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.06, 0.06, size=stp.d_buffers.shape)\n",
    "    P.fill1 = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "    \n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except:\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ifills0 = []\n",
    "ifills1 = []\n",
    "for p in gpolys:\n",
    "    ifills0.append(p.fill0.intersection(p.p.buffer(1e-6)))\n",
    "    ifills1.append(p.fill1.intersection(p.p.buffer(1e-6)))\n",
    "    \n",
    "ifills0 = [l for l in ifills0 if l.length > 1e-1]\n",
    "ifills1 = [l for l in ifills1 if l.length > 1e-1]\n",
    "\n",
    "layers = []\n",
    "layers.append(gp.merge_LineStrings(ifills0))\n",
    "layers.append(gp.merge_LineStrings(ifills1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0087_perlin_flow_erode_frays_color_mix.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'linesimplify --tolerance 0.2mm linemerge --tolerance 0.2mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## try 6 three color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 8.5 # inches\n",
    "page_y_inches: float = 11 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':1,\n",
    "    'ystep':1,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0063,\n",
    "    'noiseSeed':8\n",
    "}\n",
    "buffer_style = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "start_area = drawbox.centroid.buffer(brad*0.47)\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=15, ystep=15)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_fills = 3\n",
    "fill_angles = [-30, -90, -150]\n",
    "n_iter_choices = np.array(list(itertools.product(*[[2, 100]] * n_fills)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=30, xscale=7, yscale=7)\n",
    "    pc.init_particles(start_bounds=drawbox)\n",
    "    n_steps = np.random.randint(low=10, high=100, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.3, high=2.7) + np.random.uniform(low=0., high=0.7, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "    P.fills = []\n",
    "    n_iter_choice = n_iter_choices[np.random.choice(n_iter_choices.shape[0])]\n",
    "    for i in range(n_fills):\n",
    "        stp = ScaleTransPrms(\n",
    "            n_iters=n_iter_choice[i],\n",
    "            d_buffer=np.random.uniform(low=-0.6, high=-0.25),\n",
    "            d_translate_factor=0.7,\n",
    "            angles=np.radians(fill_angles[i]),)\n",
    "        stp.d_buffers += np.random.uniform(-0.1, 0.1, size=stp.d_buffers.shape)\n",
    "        fill = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "        P.fills.append(fill)\n",
    "    \n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except:\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fill_sets = []\n",
    "for i in range(n_fills):\n",
    "    fill_sets.append([])\n",
    "    \n",
    "for p in gpolys:\n",
    "    for i in range(n_fills):\n",
    "        fill_sets[i].append(p.fills[i].intersection(p.p.buffer(1e-6)))\n",
    "\n",
    "layers = []\n",
    "for fill_set in fill_sets:\n",
    "    filter_fills = [l for l in fill_set if l.length > 0.2]\n",
    "    layers.append(gp.merge_LineStrings(filter_fills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0088_perlin_flow_erode_frays_color_mix.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'linesimplify --tolerance 0.2mm linemerge --tolerance 0.2mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# try 7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 8.5 # inches\n",
    "page_y_inches: float = 11 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':1,\n",
    "    'ystep':1,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0063,\n",
    "    'noiseSeed':8\n",
    "}\n",
    "buffer_style = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "# start_area = drawbox.centroid.buffer(brad*0.47)\n",
    "start_area = drawbox\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=35, ystep=35)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_fills = 3\n",
    "fill_angles = [-30, -90, -150]\n",
    "n_iter_choices = np.array(list(itertools.product(*[[0, 100]] * n_fills)))\n",
    "n_iter_choices = n_iter_choices[1:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=60, xscale=6, yscale=6)\n",
    "    pc.init_particles(start_bounds=drawbox)\n",
    "    n_steps = np.random.randint(low=4, high=7, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.3, high=0.7) + np.random.uniform(low=0., high=3.7, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "    P.fills = []\n",
    "    n_iter_choice = n_iter_choices[np.random.choice(n_iter_choices.shape[0])]\n",
    "    for i in range(n_fills):\n",
    "        stp = ScaleTransPrms(\n",
    "            n_iters=n_iter_choice[i],\n",
    "            d_buffer=np.random.uniform(low=-0.6, high=-0.25),\n",
    "            d_translate_factor=0.7,\n",
    "            angles=np.radians(fill_angles[i]),)\n",
    "        stp.d_buffers += np.random.uniform(-0.1, 0.1, size=stp.d_buffers.shape)\n",
    "        fill = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "        P.fills.append(fill)\n",
    "    \n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except:\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fill_sets = []\n",
    "for i in range(n_fills):\n",
    "    fill_sets.append([])\n",
    "    \n",
    "for p in gpolys:\n",
    "    for i in range(n_fills):\n",
    "        fill_sets[i].append(p.fills[i].intersection(p.p.buffer(1e-6)))\n",
    "\n",
    "layers = []\n",
    "for fill_set in fill_sets:\n",
    "    filter_fills = [l for l in fill_set if l.length > 0.2]\n",
    "    layers.append(gp.merge_LineStrings(filter_fills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0090_perlin_flow_erode_frays_color_mix.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'linesimplify --tolerance 0.2mm linemerge --tolerance 0.2mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## try 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 8.5 # inches\n",
    "page_y_inches: float = 11 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':3,\n",
    "    'ystep':3,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0013,\n",
    "    'noiseSeed':8\n",
    "}\n",
    "buffer_style = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "# start_area = drawbox.centroid.buffer(brad*0.47)\n",
    "start_area = drawbox.buffer(-5, cap_style=3, join_style=3)\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=15, ystep=15)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(6,6))\n",
    "ax.quiver(np.cos(pg.a), np.sin(pg.a), scale=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_fills = 3\n",
    "fill_angles = [-30, -40, -50]\n",
    "n_iter_choices = np.array(list(itertools.product(*[[0, 100]] * n_fills)))\n",
    "n_iter_choices = n_iter_choices[1:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=15, xscale=3, yscale=3)\n",
    "    pc.init_particles(start_bounds=drawbox)\n",
    "    n_steps = np.random.randint(low=1, high=15, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.1, high=1.7) + np.random.uniform(low=0., high=0.3, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "    P.fills = []\n",
    "    n_iter_choice = n_iter_choices[np.random.choice(n_iter_choices.shape[0])]\n",
    "    for i in range(n_fills):\n",
    "        stp = ScaleTransPrms(\n",
    "            n_iters=n_iter_choice[i],\n",
    "            d_buffer=np.random.uniform(low=-0.6, high=-0.2),\n",
    "            d_translate_factor=0.8,\n",
    "            angles=np.radians(fill_angles[i]),)\n",
    "        stp.d_buffers += np.random.uniform(-0.1, 0.1, size=stp.d_buffers.shape)\n",
    "        fill = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "        P.fills.append(fill)\n",
    "    \n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except:\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fill_sets = []\n",
    "for i in range(n_fills):\n",
    "    fill_sets.append([])\n",
    "    \n",
    "for p in gpolys:\n",
    "    for i in range(n_fills):\n",
    "        fill_sets[i].append(p.fills[i].intersection(p.p.buffer(1e-6)))\n",
    "\n",
    "layers = []\n",
    "for fill_set in fill_sets:\n",
    "    filter_fills = [l for l in fill_set if l.length > 0.2]\n",
    "    layers.append(gp.merge_LineStrings(filter_fills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0091_perlin_flow_erode_frays_color_mix.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'reloop linesimplify --tolerance 0.2mm linemerge --tolerance 0.2mm linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# try 9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 6 # inches\n",
    "page_y_inches: float = 6 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':1,\n",
    "    'ystep':1,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0063,\n",
    "    'noiseSeed':8\n",
    "}\n",
    "buffer_style = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "# start_area = drawbox.centroid.buffer(brad*0.47)\n",
    "start_area = drawbox.buffer(-10)\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=25, ystep=25)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_fills = 3\n",
    "fill_angles = [-30, -90, -150]\n",
    "n_iter_choices = np.array(list(itertools.product(*[[0, 100]] * n_fills)))\n",
    "n_iter_choices = n_iter_choices[1:-1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=30, xscale=5, yscale=5)\n",
    "    pc.init_particles(start_bounds=start_area)\n",
    "    n_steps = np.random.randint(low=4, high=17, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.3, high=0.7) + np.random.uniform(low=0., high=3.7, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "    P.fills = []\n",
    "    n_iter_choice = n_iter_choices[np.random.choice(n_iter_choices.shape[0])]\n",
    "    for i in range(n_fills):\n",
    "        stp = ScaleTransPrms(\n",
    "            n_iters=n_iter_choice[i],\n",
    "            d_buffer=np.random.uniform(low=-0.6, high=-0.25),\n",
    "            d_translate_factor=0.7,\n",
    "            angles=np.radians(fill_angles[i]),)\n",
    "        stp.d_buffers += np.random.uniform(-0.1, 0.1, size=stp.d_buffers.shape)\n",
    "        fill = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "        P.fills.append(fill)\n",
    "    \n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except:\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fill_sets = []\n",
    "for i in range(n_fills):\n",
    "    fill_sets.append([])\n",
    "    \n",
    "for p in gpolys:\n",
    "    for i in range(n_fills):\n",
    "        fill_sets[i].append(p.fills[i].intersection(p.p.buffer(1e-6)))\n",
    "\n",
    "layers = []\n",
    "for fill_set in fill_sets:\n",
    "    filter_fills = [l for l in fill_set if l.length > 0.2]\n",
    "    layers.append(gp.merge_LineStrings(filter_fills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0092_perlin_flow_erode_frays_color_mix.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'reloop linesimplify --tolerance 0.2mm linemerge --tolerance 0.2mm linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# try 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 8.5 # inches\n",
    "page_y_inches: float = 11 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':3,\n",
    "    'ystep':3,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0013,\n",
    "    'noiseSeed':8\n",
    "}\n",
    "buffer_style = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "# start_area = drawbox.centroid.buffer(brad*0.47)\n",
    "start_area = drawbox.buffer(-5, cap_style=3, join_style=3)\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=25, ystep=25)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(6,6))\n",
    "ax.quiver(np.cos(pg.a), np.sin(pg.a), scale=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_fills = 2\n",
    "fill_angles = [-30, -40, ]\n",
    "n_iter_choices = np.array(list(itertools.product(*[[0, 100]] * n_fills)))\n",
    "n_iter_choices = n_iter_choices[[-1], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=35, xscale=5, yscale=5)\n",
    "    pc.init_particles(start_bounds=drawbox)\n",
    "    n_steps = np.random.randint(low=1, high=15, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.1, high=1.7) + np.random.uniform(low=0., high=0.3, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "    P.fills = []\n",
    "    n_iter_choice = n_iter_choices[np.random.choice(n_iter_choices.shape[0])]\n",
    "    for i in range(n_fills):\n",
    "        stp = ScaleTransPrms(\n",
    "            n_iters=n_iter_choice[i],\n",
    "            d_buffer=np.random.uniform(low=-0.6, high=-0.2),\n",
    "            d_translate_factor=0.8,\n",
    "            angles=np.radians(fill_angles[i]),)\n",
    "        stp.d_buffers += np.random.uniform(-0.1, 0.1, size=stp.d_buffers.shape)\n",
    "        fill = gp.merge_LineStrings([p.boundary for p in gp.scale_trans(P.p, **stp.prms)])\n",
    "        P.fills.append(fill)\n",
    "    \n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except:\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "fill_sets = []\n",
    "for i in range(n_fills):\n",
    "    fill_sets.append([])\n",
    "    \n",
    "for p in gpolys:\n",
    "    for i in range(n_fills):\n",
    "        fill_sets[i].append(p.fills[i].intersection(p.p.buffer(1e-6)))\n",
    "\n",
    "layers = []\n",
    "for fill_set in fill_sets:\n",
    "    filter_fills = [l for l in fill_set if l.length > 0.2]\n",
    "    layers.append(gp.merge_LineStrings(filter_fills))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0093_perlin_flow_erode_frays.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'reloop linesimplify --tolerance 0.2mm linemerge --tolerance 0.2mm linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# try 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 11 # inches\n",
    "page_y_inches: float = 8.5 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':3,\n",
    "    'ystep':3,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0053,\n",
    "    'noiseSeed':3\n",
    "}\n",
    "buffer_style = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "start_area = drawbox.buffer(-10, cap_style=3, join_style=3)\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=25, ystep=35)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(6,6))\n",
    "ax.quiver(np.cos(pg.a), np.sin(pg.a), scale=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=40, xscale=5, yscale=5)\n",
    "    pc.init_particles(start_bounds=start_area)\n",
    "    n_steps = np.random.randint(low=3, high=20, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "\n",
    "    buffer_distances = np.random.uniform(low=0.3, high=3.3) + np.random.uniform(low=0., high=1.7, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "\n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.75, high=-0.3), \n",
    "        angles=-90,\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.03, 0.03, size=stp.d_buffers.shape)\n",
    "    P.fill_scale_trans(**stp.prms)\n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except :\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ifills = []\n",
    "for p in gpolys:\n",
    "    try:\n",
    "        ifills.append(p.intersection_fill)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "splits = utils.random_split(ifills, n_layers=5)\n",
    "layers = [gp.merge_LineStrings(split) for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0100_perlin_flow_erode_frays_occlude.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'reloop linesimplify --tolerance 0.01mm linemerge --tolerance 0.1mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# try 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 11 # inches\n",
    "page_y_inches: float = 8.5 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':3,\n",
    "    'ystep':3,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0083,\n",
    "    'noiseSeed':3\n",
    "}\n",
    "buffer_style = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "start_area = drawbox.buffer(-10, cap_style=3, join_style=3)\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=15, ystep=55)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "f,ax = plt.subplots(figsize=(6,6))\n",
    "ax.quiver(np.cos(pg.a), np.sin(pg.a), scale=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=60, xscale=7, yscale=12)\n",
    "    pc.init_particles(start_bounds=start_area)\n",
    "    n_steps = np.random.randint(low=1, high=15, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "    \n",
    "    buffer_distances = np.random.uniform(low=0.3, high=6.3) + np.random.uniform(low=0., high=0.5, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        bd = np.interp(line.centroid.x, [10, 270], [0.1, 3])\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "\n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.65, high=-0.3), \n",
    "        angles=-90,\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.03, 0.03, size=stp.d_buffers.shape)\n",
    "    P.fill_scale_trans(**stp.prms)\n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except :\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ifills = []\n",
    "for p in gpolys:\n",
    "    try:\n",
    "        ifills.append(p.intersection_fill)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "splits = utils.random_split(ifills, n_layers=5)\n",
    "layers = [gp.merge_LineStrings(split) for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0101_perlin_flow_erode_frays_occlude.svg'\n",
    "\n",
    "sk.save(savepath)\n",
    "\n",
    "vpype_commands = 'reloop linesimplify --tolerance 0.01mm linemerge --tolerance 0.1mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write --page-format {page_format} {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# try 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "page_x_inches: float = 11 # inches\n",
    "page_y_inches: float = 8.5 # inches\n",
    "border:float = 0.\n",
    "\n",
    "perlin_grid_params = {\n",
    "    'xstep':1,\n",
    "    'ystep':1,\n",
    "    'lod':10,\n",
    "    'falloff':None,\n",
    "    'noise_scale':0.0193,\n",
    "    'noiseSeed':3\n",
    "}\n",
    "buffer_style = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "px = utils.DistanceConverter(page_x_inches, 'inches').mm\n",
    "py = utils.DistanceConverter(page_y_inches, 'inches').mm\n",
    "page_format = f'{px}mmx{py}mm'\n",
    "drawbox = sg.box(border, border, px-border, py-border)\n",
    "\n",
    "xmin, ymin, xmax, ymax = drawbox.bounds\n",
    "brad = np.min([gp.get_width(drawbox), gp.get_height(drawbox)])\n",
    "\n",
    "start_area = drawbox.buffer(-10, cap_style=3, join_style=3)\n",
    "pg = gp.PerlinGrid(start_area, **perlin_grid_params)\n",
    "xcs, ycs = gp.overlay_grid(start_area, xstep=20, ystep=75)\n",
    "start_pts = [Point(x,y) for x,y in itertools.product(xcs, ycs)]\n",
    "start_pts = [p for p in start_pts if start_area.contains(p)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# f,ax = plt.subplots(figsize=(6,6))\n",
    "# ax.quiver(np.cos(pg.a), np.sin(pg.a), scale=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "gpolys = []\n",
    "for p in start_pts:\n",
    "\n",
    "    pc = ParticleCluster(pos=p, perlin_grid=pg)\n",
    "    pc.gen_start_pts_gaussian(n_particles=60, xscale=8, yscale=13)\n",
    "    pc.init_particles(start_bounds=start_area)\n",
    "    n_steps = int(np.interp(pc.pos.centroid.x, [1, 270], [1, 30]))\n",
    "#     n_steps = np.random.randint(low=1, high=15, size=len(pc.particles))\n",
    "    pc.step(n_steps)\n",
    "    \n",
    "    buffer_distances = np.random.uniform(low=0.3, high=6.3) + np.random.uniform(low=0., high=0.5, size=len(pc.lines))\n",
    "    polys = []\n",
    "    for line, bd in zip(pc.lines, buffer_distances):\n",
    "        bd = np.interp(line.centroid.x, [10, 270], [0.1, 3.5])\n",
    "        poly = line.buffer(bd,\n",
    "            cap_style=buffer_style,\n",
    "            join_style=buffer_style)\n",
    "        polys.append(poly)\n",
    "\n",
    "    P = gp.Poly(so.unary_union(polys))\n",
    "\n",
    "    stp = ScaleTransPrms(\n",
    "        d_buffer=np.random.uniform(low=-0.4, high=-0.2), \n",
    "        angles=-60,\n",
    "\n",
    "    )\n",
    "    stp.d_buffers += np.random.uniform(-0.06, 0.06, size=stp.d_buffers.shape)\n",
    "    P.fill_scale_trans(**stp.prms)\n",
    "    gpolys.append(P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "zorder = np.random.permutation(len(gpolys))\n",
    "\n",
    "for z, gpoly in zip(zorder, gpolys):\n",
    "    gpoly.z = z\n",
    "\n",
    "for gp0, gp1 in itertools.combinations(gpolys, r=2):\n",
    "    try:\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    except :\n",
    "        gp0.p = gp0.p.buffer(1e-6)\n",
    "        gp1.p = gp1.p.buffer(1e-6)\n",
    "        overlaps = gp0.p.overlaps(gp1.p)\n",
    "    if overlaps:\n",
    "        if gp0.z > gp1.z:\n",
    "            gp1.p = occlude(top=gp0.p, bottom=gp1.p)\n",
    "        elif gp0.z < gp1.z:\n",
    "            gp0.p = occlude(top=gp1.p, bottom=gp0.p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ifills = []\n",
    "for p in gpolys:\n",
    "    try:\n",
    "        ifills.append(p.intersection_fill)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "splits = utils.random_split(ifills, n_layers=5)\n",
    "layers = [gp.merge_LineStrings(split) for split in splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(page_format)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.25mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "sk.display(color_mode='none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "savepath = '/mnt/c/code/side/plotter_images/oned_outputs/0102_perlin_flow_erode_frays_occlude.svg'\n",
    "\n",
    "sk.save(savepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "vpype_commands = 'reloop linesimplify --tolerance 0.01mm linemerge --tolerance 0.1mm reloop linesort'\n",
    "vpype_str = f'vpype read -q 0.05mm {savepath} {vpype_commands} write {savepath}'\n",
    "\n",
    "os.system(vpype_str)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:genpen]",
   "language": "python",
   "name": "conda-env-genpen-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
