{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f5e1c8-8335-43a2-be12-64bf1581343e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import itertools\n",
    "import numpy as np\n",
    "import os\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from dataclasses import asdict, dataclass, field\n",
    "import vsketch\n",
    "import shapely.geometry as sg\n",
    "from shapely.geometry import box, MultiLineString, Point, MultiPoint, Polygon, MultiPolygon, LineString\n",
    "import shapely.affinity as sa\n",
    "import shapely.ops as so\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "import vpype_cli\n",
    "from typing import List, Generic\n",
    "from genpen import genpen as gp\n",
    "from genpen.utils import Paper\n",
    "from scipy import stats\n",
    "import geopandas\n",
    "from shapely.errors import TopologicalError\n",
    "import functools\n",
    "import vpype\n",
    "from skimage import io\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from skimage import feature\n",
    "from skimage import exposure\n",
    "\n",
    "from skimage import filters\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from skimage.morphology import disk\n",
    "from numpy.random import default_rng\n",
    "\n",
    "def local_angle(dx, dy):\n",
    "    \"\"\"Calculate the angles between horizontal and vertical operators.\"\"\"\n",
    "    return np.mod(np.arctan2(dy, dx), np.pi)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import cv2\n",
    "from rasterio import features\n",
    "import rasterio\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7ad548-3d23-4200-b68d-6d16933f9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydiffvg as dg\n",
    "import torch\n",
    "import skimage\n",
    "import numpy as np\n",
    "from torchvision.transforms import functional as TF\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9d8070-9a47-4e8d-90ee-ef4d3d992606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finalize_image(img, gamma = 2.2, normalize = False, as_Image=False):\n",
    "    if not isinstance(img, np.ndarray):\n",
    "        img = img.data.numpy()\n",
    "    if normalize:\n",
    "        img_rng = np.max(img) - np.min(img)\n",
    "        if img_rng > 0:\n",
    "            img = (img - np.min(img)) / img_rng\n",
    "    img = np.clip(img, 0.0, 1.0)\n",
    "    if img.ndim==2:\n",
    "        #repeat along the third dimension\n",
    "        img=np.expand_dims(img,2)\n",
    "    img[:, :, :3] = np.power(img[:, :, :3], 1.0/gamma)\n",
    "    img = (img * 255).astype(np.uint8)\n",
    "    if as_Image:\n",
    "        img = Image.fromarray(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d547ad4-93ac-476d-b7f4-a9f078742032",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LineTensor(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        linestring,\n",
    "    ):\n",
    "        self.init_ls = linestring\n",
    "        self.pts = [p for p in self.init_ls.coords]\n",
    "        self.tensor = torch.tensor(self.pts, requires_grad=True)\n",
    "        self.init_loc_pt = self.ls.centroid\n",
    "        self.init_loc_tensor = torch.tensor(np.array(self.init_loc_pt), requires_grad=True)\n",
    "        \n",
    "    @property\n",
    "    def ls(self):\n",
    "        return LineString(self.tensor.cpu().data.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebbddd94-e46f-47b2-a4a9-ceed953d47aa",
   "metadata": {},
   "source": [
    "# diffvg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28874d7-f548-4947-87f5-637e2e7fb2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d02998-e1c7-4c1b-a7bf-26b001a637b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SpinLine(object):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        offset_xy=None,\n",
    "        angular_loc_deg=0.,\n",
    "        radial_loc=0.,\n",
    "        rotation_deg=0.,\n",
    "        length=1.\n",
    "    ):\n",
    "        if offset_xy is None:\n",
    "            offset_xy = np.array((0., 0.))\n",
    "        self.offset_xy = offset_xy\n",
    "        self.theta = angular_loc_deg\n",
    "        self.r = radial_loc\n",
    "        self.deg = rotation_deg\n",
    "        self.length = length\n",
    "        self.x = np.cos(self.theta) * self.r\n",
    "        self.y = np.sin(self.theta) * self.r\n",
    "        self.loc = np.array((self.x, self.y)) + self.offset_xy\n",
    "        self.rel_coords = [np.array((np.cos(self.deg), np.sin(self.deg))) * self.length/2 * ii for ii in [-1, 1]]\n",
    "        self.coords = [c + self.loc for c in self.rel_coords]\n",
    "        self.line = LineString(self.coords)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b0498-c89b-4334-b192-ff2de57bd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "dg.set_use_gpu(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304d9a5-5afd-4f2e-9e00-fcc66ae993b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1200\n",
    "height = 1600\n",
    "drawbox = box(0, 0, width, height)\n",
    "db = gp.Shape(drawbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9bd3a0-b368-488c-83a6-e2738e46afea",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawbox = box(0, 0, width, height)\n",
    "db = gp.Shape(drawbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7d985-7558-4e6d-8644-ebb70a6b4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_shape = np.array((db.height, db.width)).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675499ce-8610-44ee-9356-45ae41bf6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_id = fn.new_nft_id()\n",
    "\n",
    "raster_videos_dir = Path('/home/naka/art/raster_videos')\n",
    "nft_dir = raster_videos_dir.joinpath(nft_id)\n",
    "\n",
    "if not nft_dir.exists():\n",
    "    os.mkdir(nft_dir) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12835c76-4d62-4b0e-a5b8-f1df4fa4ce7e",
   "metadata": {},
   "source": [
    "# single"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a5a9ec-88b9-429c-b0bf-42c1dcd414ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "t=0.00\n",
    "center = np.array(db.p.centroid.xy).ravel()\n",
    "n_circles = 7\n",
    "max_rad = (db.width/2) * 0.8\n",
    "min_rad = (db.width/2) * 0.05\n",
    "radii = np.linspace(min_rad, max_rad, n_circles)\n",
    "loc_xy_spacing = 55\n",
    "sls = []\n",
    "\n",
    "for radius in radii:\n",
    "    circumference = radius * 360\n",
    "    angular_locs = np.arange(0, circumference, loc_xy_spacing) / radius\n",
    "    for angular_loc_deg in angular_locs:\n",
    "        rotation_deg = angular_loc_deg * 4 + 60 * np.sin(0.01 * angular_loc_deg * t + 0.02*radius) + np.sin(0.00013 * angular_loc_deg) * 20\n",
    "        length = 8. + np.sin(radius * angular_loc_deg) * 90 + np.sin(angular_loc_deg*0.001) * 40 + np.sin(0.00013 * angular_loc_deg) * 70\n",
    "        rad = radius + np.sin(t * angular_loc_deg) * 20\n",
    "        sl = SpinLine(offset_xy=center, angular_loc_deg=angular_loc_deg, radial_loc=rad, rotation_deg=rotation_deg, length=length)\n",
    "        sls.append(LineString(sl.coords))\n",
    "\n",
    "gp.merge_LineStrings(sls)\n",
    "\n",
    "lts = [LineTensor(ls) for ls in sls]\n",
    "\n",
    "canvas_width, canvas_height = width, height\n",
    "num_control_points = torch.tensor([0])\n",
    "shapes = []\n",
    "shape_groups = []\n",
    "for ii, lt in enumerate(lts):\n",
    "    path = dg.Path(num_control_points = num_control_points,\n",
    "                         points = lt.tensor,\n",
    "                         is_closed = False,\n",
    "                         stroke_width = torch.tensor(0.1))\n",
    "    shapes.append(path)\n",
    "    path_group = dg.ShapeGroup(shape_ids = torch.tensor([ii]),\n",
    "                                     fill_color = torch.tensor([0.0, 0.0, 0.0, 0.0]),\n",
    "                                     stroke_color = torch.tensor([1., 1., 1., 1]))\n",
    "    shape_groups.append(path_group)\n",
    "\n",
    "\n",
    "scene_args = dg.RenderFunction.serialize_scene(\\\n",
    "    canvas_width, canvas_height, shapes, shape_groups)\n",
    "render = dg.RenderFunction.apply\n",
    "img = render(canvas_width, # width\n",
    "             canvas_height, # height\n",
    "             2,   # num_samples_x\n",
    "             2,   # num_samples_y\n",
    "             0,   # seed\n",
    "             None, # background_image\n",
    "             *scene_args)\n",
    "# target = img.clone()\n",
    "\n",
    "angle_targets = [torch.tensor(0) for shape in shapes]\n",
    "\n",
    "# init\n",
    "rendered_img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "img = render(canvas_width, # width\n",
    "             canvas_height, # height\n",
    "             2,   # num_samples_x\n",
    "             2,   # num_samples_y\n",
    "             0,   # seed\n",
    "             None, # background_image\n",
    "             *scene_args)\n",
    "img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "\n",
    "background = Image.new('RGBA', img.size, (0, 0, 0))\n",
    "\n",
    "alpha_composite = Image.alpha_composite(background, img)\n",
    "alpha_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af111d85-44fa-4c0b-afe9-9fa1e9af2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_val = 100\n",
    "now = fn.get_time()\n",
    "filepath = nft_dir.joinpath(f'{nft_id}_{now}_0000.jpeg')\n",
    "alpha_composite.convert('RGB').save(filepath, quality=quality_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36fb3061-046c-4a92-8849-e2bd3b0ae3d6",
   "metadata": {},
   "source": [
    "# movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef769e70-fc56-4768-b8a1-44c6d89f1fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ts = np.arange(0., 1., 0.001)\n",
    "quality_val = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ac834a-a4fd-4dcb-a2a4-e70c544df933",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img_no, t in enumerate(tqdm(ts)):\n",
    "    center = np.array(db.p.centroid.xy).ravel()\n",
    "    n_circles = 10\n",
    "    max_rad = (db.width/2) * 0.8\n",
    "    min_rad = (db.width/2) * 0.05\n",
    "    radii = np.linspace(min_rad, max_rad, n_circles)\n",
    "    loc_xy_spacing = 85\n",
    "    sls = []\n",
    "\n",
    "    for radius in radii:\n",
    "        circumference = radius * 360\n",
    "        angular_locs = np.arange(0, circumference, loc_xy_spacing) / radius\n",
    "        for angular_loc_deg in angular_locs:\n",
    "            rotation_deg = angular_loc_deg * 0.5 + 40 * np.sin(t* 0.001 * radius ) + 40 * np.sin(0.01 * angular_loc_deg * t)\n",
    "            length = 88. + np.sin(t)\n",
    "            sl = SpinLine(offset_xy=center, angular_loc_deg=angular_loc_deg, radial_loc=radius, rotation_deg=rotation_deg, length=length)\n",
    "            sls.append(LineString(sl.coords))\n",
    "\n",
    "    gp.merge_LineStrings(sls)\n",
    "\n",
    "    lts = [LineTensor(ls) for ls in sls]\n",
    "\n",
    "    canvas_width, canvas_height = width, height\n",
    "    num_control_points = torch.tensor([0])\n",
    "    shapes = []\n",
    "    shape_groups = []\n",
    "    for ii, lt in enumerate(lts):\n",
    "        path = dg.Path(num_control_points = num_control_points,\n",
    "                             points = lt.tensor,\n",
    "                             is_closed = False,\n",
    "                             stroke_width = torch.tensor(0.1))\n",
    "        shapes.append(path)\n",
    "        path_group = dg.ShapeGroup(shape_ids = torch.tensor([ii]),\n",
    "                                         fill_color = torch.tensor([0.0, 0.0, 0.0, 0.0]),\n",
    "                                         stroke_color = torch.tensor([1., 1., 1., 1]))\n",
    "        shape_groups.append(path_group)\n",
    "\n",
    "\n",
    "    scene_args = dg.RenderFunction.serialize_scene(\\\n",
    "        canvas_width, canvas_height, shapes, shape_groups)\n",
    "    render = dg.RenderFunction.apply\n",
    "    img = render(canvas_width, # width\n",
    "                 canvas_height, # height\n",
    "                 2,   # num_samples_x\n",
    "                 2,   # num_samples_y\n",
    "                 0,   # seed\n",
    "                 None, # background_image\n",
    "                 *scene_args)\n",
    "    # target = img.clone()\n",
    "\n",
    "    angle_targets = [torch.tensor(0) for shape in shapes]\n",
    "\n",
    "    # init\n",
    "    rendered_img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "    img = render(canvas_width, # width\n",
    "                 canvas_height, # height\n",
    "                 2,   # num_samples_x\n",
    "                 2,   # num_samples_y\n",
    "                 0,   # seed\n",
    "                 None, # background_image\n",
    "                 *scene_args)\n",
    "    img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "\n",
    "    background = Image.new('RGBA', img.size, (0, 0, 0))\n",
    "\n",
    "    alpha_composite = Image.alpha_composite(background, img)\n",
    "    filepath = nft_dir.joinpath(f'{nft_id}_{img_no:0004}.jpeg')\n",
    "    alpha_composite.convert('RGB').save(filepath, quality=quality_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67631692-1a85-4877-809a-b11b1047349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [fp.as_posix() for fp in nft_dir.glob('.jpeg)')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0114e71e-caab-44f5-996a-2d978097fc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import moviepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083dc7be-03f3-43e5-a6e8-2d27ea537bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipout = moviepy.video.io.ImageSequenceClip.ImageSequenceClip(filenames, fps=10)\n",
    "clipout.write_videofile(nft_dir.joinpathnpath(f'{nft_id}.mp4'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b92b2f-1789-43ea-a0f1-ed6da246f8de",
   "metadata": {},
   "source": [
    "# moire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809b4d14-9d38-4737-8f9a-c12776ca99e0",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "from skimage import feature\n",
    "from genpen.utils import Paper\n",
    "\n",
    "from scipy import spatial, stats\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from scipy.integrate import odeint\n",
    "# make page\n",
    "paper_size = '11x14 inches'\n",
    "border:float=30\n",
    "paper = Paper(paper_size)\n",
    "\n",
    "drawbox = paper.get_drawbox(border)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7bd637-186e-45a3-9dcb-42fdd316e56a",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "center = drawbox.centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "facdce3c-2254-46e3-aa8e-948ca0681ee8",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_lines = 8421\n",
    "thetas = np.linspace(0, np.pi*27, n_lines)\n",
    "radii = np.linspace(0.8, 28, n_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76da2aae-20b2-41e5-b251-cd901b43f50b",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "pts = []\n",
    "for theta, radius in zip(thetas, radii):\n",
    "    x = np.cos(theta) * radius - 0\n",
    "    y = np.sin(theta) * radius + 0.\n",
    "    pts.append(Point(x, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f27f0fa-dd81-480c-9338-0534a9e30269",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ode(y, t, a, b, c, d):\n",
    "    v, u = y\n",
    "    dvdt = np.sin(b * u) + v * c\n",
    "    dudt = np.cos(a * v * u) + u  * d\n",
    "    dydt = [dvdt, dudt]\n",
    "    return dydt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a454747-d1ed-468e-96fa-6ec9b8cb899a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "t_max = 5.7\n",
    "t = np.linspace(0, t_max, 41)\n",
    "a = 0.1\n",
    "b = 0.95\n",
    "c = - 0.02\n",
    "d = -0.02\n",
    "\n",
    "all_polys = Polygon()\n",
    "\n",
    "break_dist = 0.01\n",
    "\n",
    "lines = []\n",
    "lfs = MultiLineString()\n",
    "allowed_counter = 0\n",
    "for ii, pt in enumerate(tqdm(pts)):\n",
    "    sol = odeint(ode, [pt.x, pt.y], t, args=(a, b, c, d))\n",
    "    mpt = MultiPoint(sol)\n",
    "    if ii == 0:\n",
    "        ls = LineString(mpt)\n",
    "        lfs = gp.merge_LineStrings([lfs, ls])\n",
    "        lines.append(ls)\n",
    "    else:\n",
    "        allowed_counter = 0\n",
    "        for _pt in mpt:\n",
    "            dist = _pt.distance(lfs)\n",
    "            # if dist < break_dist:\n",
    "            #     break\n",
    "            allowed_counter += 1\n",
    "    if allowed_counter > 1:\n",
    "        ls = LineString(mpt[:allowed_counter])\n",
    "        lfs = gp.merge_LineStrings([lfs, ls])\n",
    "        lines.append(ls)\n",
    "        \n",
    "lbs0 = gp.merge_LineStrings([l for l in lines if l.length > 0.9])     \n",
    "lbs0 = gp.make_like(gp.merge_LineStrings(lbs0), drawbox)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d26fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "dg.set_use_gpu(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b8338a",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 2000\n",
    "height = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawbox = box(0, 0, width, height)\n",
    "db = gp.Shape(drawbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308e6819",
   "metadata": {},
   "outputs": [],
   "source": [
    "sls = gp.make_like(gp.merge_LineStrings(lbs0), drawbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c7d985-7558-4e6d-8644-ebb70a6b4e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_shape = np.array((db.height, db.width)).round().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675499ce-8610-44ee-9356-45ae41bf6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_id = fn.new_nft_id()\n",
    "\n",
    "raster_videos_dir = Path('/home/naka/art/raster_videos')\n",
    "nft_dir = raster_videos_dir.joinpath(nft_id)\n",
    "\n",
    "if not nft_dir.exists():\n",
    "    os.mkdir(nft_dir) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1af07d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "sls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7759d763",
   "metadata": {},
   "outputs": [],
   "source": [
    "lts = []\n",
    "for ls in sls:\n",
    "    for ii in range(len(ls.coords)-1):\n",
    "        sub_ls = LineString(ls.coords[ii:ii+2])\n",
    "        lt = LineTensor(sub_ls)\n",
    "        lts.append(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f5d57c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "canvas_width, canvas_height = width, height\n",
    "num_control_points = torch.tensor([0])\n",
    "shapes = []\n",
    "shape_groups = []\n",
    "for ii, lt in enumerate(lts):\n",
    "    path = dg.Path(num_control_points = num_control_points,\n",
    "                         points = lt.tensor,\n",
    "                         is_closed = False,\n",
    "                         stroke_width = torch.tensor(0.45))\n",
    "    shapes.append(path)\n",
    "    path_group = dg.ShapeGroup(shape_ids = torch.tensor([ii]),\n",
    "                                     fill_color = torch.tensor([0.0, 0.0, 0.0, 0.0]),\n",
    "                                     stroke_color = torch.tensor([1., 1., 1., 0.6]))\n",
    "    shape_groups.append(path_group)\n",
    "\n",
    "\n",
    "scene_args = dg.RenderFunction.serialize_scene(\\\n",
    "    canvas_width, canvas_height, shapes, shape_groups)\n",
    "render = dg.RenderFunction.apply\n",
    "img = render(canvas_width, # width\n",
    "             canvas_height, # height\n",
    "             2,   # num_samples_x\n",
    "             2,   # num_samples_y\n",
    "             0,   # seed\n",
    "             None, # background_image\n",
    "             *scene_args)\n",
    "# target = img.clone()\n",
    "\n",
    "angle_targets = [torch.tensor(0) for shape in shapes]\n",
    "\n",
    "# init\n",
    "rendered_img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "img = render(canvas_width, # width\n",
    "             canvas_height, # height\n",
    "             2,   # num_samples_x\n",
    "             2,   # num_samples_y\n",
    "             0,   # seed\n",
    "             None, # background_image\n",
    "             *scene_args)\n",
    "img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "\n",
    "background = Image.new('RGBA', img.size, (0, 0, 0))\n",
    "\n",
    "alpha_composite = Image.alpha_composite(background, img)\n",
    "alpha_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af111d85-44fa-4c0b-afe9-9fa1e9af2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_val = 100\n",
    "now = fn.get_time()\n",
    "filepath = nft_dir.joinpath(f'{nft_id}_{now}_0000.jpeg')\n",
    "alpha_composite.convert('RGB').save(filepath, quality=quality_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2949d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from genpen import subdivide as sd\n",
    "from functools import partial\n",
    "from genpen.grower import Grower, GrowerParams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b0498-c89b-4334-b192-ff2de57bd621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use GPU if available\n",
    "dg.set_use_gpu(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f445d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "drawbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bc93cd-69ca-4808-8183-0de9f704d479",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# make page\n",
    "paper_size = 'A2'\n",
    "border:float=45\n",
    "paper = Paper(paper_size)\n",
    "\n",
    "drawbox = paper.get_drawbox(border)\n",
    "\n",
    "split_func = functools.partial(sd.split_random_bezier, x0=0.2, x1=0.75, n_eval_points=50)\n",
    "\n",
    "xgen = stats.uniform(loc=0.4, scale=0.01).rvs\n",
    "split_func = functools.partial(sd.split_along_longest_side_of_min_rectangle, xgen=xgen)\n",
    "\n",
    "# x0gen = ss.uniform(loc=0.15, scale=0.01).rvs\n",
    "# x1gen = ss.uniform(loc=0.65, scale=0.01).rvs\n",
    "# split_func = functools.partial(sd.split_random_line_gen, x0gen=x0gen, x1gen=x1gen)\n",
    "\n",
    "target = Point(140, 325)\n",
    "target = drawbox.centroid\n",
    "\n",
    "dist_from_center = partial(sd.distance_from_pt, target=target, p_range=(0.99, 0.3,), d_range=(0, 200))\n",
    "cp = sd.ContinuePolicy(dist_from_center)\n",
    "polys = sd.very_flex_rule_recursive_split(poly=drawbox, split_func=split_func, continue_func=cp, depth_limit=14, buffer_kwargs={'distance':1e-6})\n",
    "\n",
    "\n",
    "bps = gp.merge_Polygons(polys)\n",
    "\n",
    "\n",
    "   \n",
    "sk = vsketch.Vsketch()\n",
    "sk.size(paper.page_format_mm)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.5mm')\n",
    "sk.geometry(bps.boundary)\n",
    "\n",
    "# tolerance=0.5\n",
    "\n",
    "sk.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e966c34-794f-4943-b6d9-b2b79cd9d04a",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_layers = 1\n",
    "\n",
    "layers = []\n",
    "\n",
    "\n",
    "for ii in range(n_layers):\n",
    "    fills = []\n",
    "    for p in bps:\n",
    "        xjitter_func = 0\n",
    "        yjitter_func = stats.norm(loc=0, scale=np.random.uniform(0.1, 1)).rvs\n",
    "        bhf = gp.BezierHatchFill(\n",
    "            spacing=np.random.uniform(0.1, 0.5),\n",
    "            degrees=np.random.uniform(10,80),\n",
    "            poly_to_fill=p, \n",
    "            xjitter_func=xjitter_func, \n",
    "            yjitter_func=yjitter_func,\n",
    "            fill_inscribe_buffer=1.4,\n",
    "            n_nodes_per_line=5,\n",
    "            n_eval_points=6,\n",
    "        )\n",
    "        fills.append(bhf.p)\n",
    "\n",
    "    fills = [f for f in fills if f.length > 0]\n",
    "    layer = gp.merge_LineStrings(fills)\n",
    "    layers.append(layer)\n",
    "\n",
    "sk = vsketch.Vsketch()\n",
    "sk.size(paper.page_format_mm)\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.3mm')\n",
    "for i, layer in enumerate(layers):\n",
    "    sk.stroke(i+1)\n",
    "    sk.geometry(layer)\n",
    "\n",
    "for tolerance in [0.1, 0.3, 0.5, 0.7]:\n",
    "    sk.vpype(f'linemerge --tolerance {tolerance}mm')\n",
    "sk.vpype('linesimplify --tolerance 0.1 linesort')\n",
    "\n",
    "sk.display(color_mode='layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3304d9a5-5afd-4f2e-9e00-fcc66ae993b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1200\n",
    "height = 1600\n",
    "drawbox = box(0, 0, width, height)\n",
    "db = gp.Shape(drawbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ea7ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sls = gp.make_like(gp.merge_LineStrings(layer), drawbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edafd6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lts = []\n",
    "for ls in sls:\n",
    "    for ii in range(len(ls.coords)-1):\n",
    "        sub_ls = LineString(ls.coords[ii:ii+2])\n",
    "        lt = LineTensor(sub_ls)\n",
    "        lts.append(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18066cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "canvas_width, canvas_height = width, height\n",
    "num_control_points = torch.tensor([0])\n",
    "shapes = []\n",
    "shape_groups = []\n",
    "for ii, lt in enumerate(lts):\n",
    "    path = dg.Path(num_control_points = num_control_points,\n",
    "                         points = lt.tensor,\n",
    "                         is_closed = False,\n",
    "                         stroke_width = torch.tensor(0.1))\n",
    "    shapes.append(path)\n",
    "    path_group = dg.ShapeGroup(shape_ids = torch.tensor([ii]),\n",
    "                                     fill_color = torch.tensor([0.0, 0.0, 0.0, 0.0]),\n",
    "                                     stroke_color = torch.tensor([1., 1., 1., 1]))\n",
    "    shape_groups.append(path_group)\n",
    "\n",
    "\n",
    "scene_args = dg.RenderFunction.serialize_scene(\\\n",
    "    canvas_width, canvas_height, shapes, shape_groups)\n",
    "render = dg.RenderFunction.apply\n",
    "img = render(canvas_width, # width\n",
    "             canvas_height, # height\n",
    "             2,   # num_samples_x\n",
    "             2,   # num_samples_y\n",
    "             0,   # seed\n",
    "             None, # background_image\n",
    "             *scene_args)\n",
    "# target = img.clone()\n",
    "\n",
    "angle_targets = [torch.tensor(0) for shape in shapes]\n",
    "\n",
    "# init\n",
    "rendered_img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "img = render(canvas_width, # width\n",
    "             canvas_height, # height\n",
    "             2,   # num_samples_x\n",
    "             2,   # num_samples_y\n",
    "             0,   # seed\n",
    "             None, # background_image\n",
    "             *scene_args)\n",
    "img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "\n",
    "background = Image.new('RGBA', img.size, (0, 0, 0))\n",
    "\n",
    "alpha_composite = Image.alpha_composite(background, img)\n",
    "alpha_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675499ce-8610-44ee-9356-45ae41bf6b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nft_id = fn.new_nft_id()\n",
    "\n",
    "raster_videos_dir = Path('/home/naka/art/raster_videos')\n",
    "nft_dir = raster_videos_dir.joinpath(nft_id)\n",
    "\n",
    "if not nft_dir.exists():\n",
    "    os.mkdir(nft_dir) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af111d85-44fa-4c0b-afe9-9fa1e9af2088",
   "metadata": {},
   "outputs": [],
   "source": [
    "quality_val = 100\n",
    "now = fn.get_time()\n",
    "filepath = nft_dir.joinpath(f'{nft_id}_{now}_0000.jpeg')\n",
    "alpha_composite.convert('RGB').save(filepath, quality=quality_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14161345",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "003fd04b",
   "metadata": {},
   "source": [
    "# simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2206e20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diffvg_images_dir = Path('/home/naka/art/diffvg_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27973872",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1600\n",
    "height = 1600\n",
    "drawbox = box(0, 0, width, height)\n",
    "db = gp.Shape(drawbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32411919",
   "metadata": {},
   "outputs": [],
   "source": [
    "paper.page_format_mm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588b99c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sk = vsketch.Vsketch()\n",
    "sk.size(f'{width}mmx{height}mm')\n",
    "sk.scale('1mm')\n",
    "sk.penWidth('0.3mm')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1fc91",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_circles = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bc399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "circles = [db.p.centroid.buffer(600) for ii in range(n_circles)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5278b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_eval_points = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd6d461",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd1d3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_filled_polys = []\n",
    "for c in circles:\n",
    "    filled = gp.BezierHatchFill(\n",
    "        poly_to_fill=c,\n",
    "        spacing=20,\n",
    "        degrees=0,\n",
    "        xjitter_func=stats.norm(loc=0, scale=0.1).rvs, \n",
    "        yjitter_func=stats.norm(loc=0, scale=5).rvs,\n",
    "        fill_inscribe_buffer=1.4,\n",
    "        n_nodes_per_line=10,\n",
    "        n_eval_points=40,\n",
    "        alternate_direction=False,\n",
    "    )\n",
    "    fills = filled.fill\n",
    "    random_walk = gp.gaussian_random_walk(len(fills), step_init=0.5, step_mu=0., step_std=3, scale=True)\n",
    "    clipped_lss = []\n",
    "    for ii, ls in enumerate(fills):\n",
    "        eval_pts = np.linspace(0, random_walk[ii], n_eval_points)\n",
    "        clipped_ls = LineString([ls.interpolate(pt, normalized=True) for pt in eval_pts])\n",
    "        clipped_lss.append(clipped_ls)\n",
    "    clipped_filled_polys.append(gp.merge_LineStrings(clipped_lss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f0c2e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp.merge_LineStrings(clipped_filled_polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a83735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sls = gp.merge_LineStrings(clipped_filled_polys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863334e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff7eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lts = []\n",
    "for ls in sls:\n",
    "    for ii in range(len(ls.coords)-1):\n",
    "        sub_ls = LineString(ls.coords[ii:ii+2])\n",
    "        lt = LineTensor(sub_ls)\n",
    "        lts.append(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4651be64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "canvas_width, canvas_height = width, height\n",
    "num_control_points = torch.tensor([0])\n",
    "shapes = []\n",
    "shape_groups = []\n",
    "for ii, lt in enumerate(lts):\n",
    "    path = dg.Path(num_control_points = num_control_points,\n",
    "                         points = lt.tensor,\n",
    "                         is_closed = False,\n",
    "                         stroke_width = torch.tensor(0.1))\n",
    "    shapes.append(path)\n",
    "    path_group = dg.ShapeGroup(shape_ids = torch.tensor([ii]),\n",
    "                                     fill_color = torch.tensor([0.0, 0.0, 0.0, 0.0]),\n",
    "                                     stroke_color = torch.tensor([1., 1., 1., 0.8]))\n",
    "    shape_groups.append(path_group)\n",
    "\n",
    "\n",
    "scene_args = dg.RenderFunction.serialize_scene(\\\n",
    "    canvas_width, canvas_height, shapes, shape_groups)\n",
    "render = dg.RenderFunction.apply\n",
    "img = render(canvas_width, # width\n",
    "             canvas_height, # height\n",
    "             4,   # num_samples_x\n",
    "             4,   # num_samples_y\n",
    "             0,   # seed\n",
    "             None, # background_image\n",
    "             *scene_args)\n",
    "img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "\n",
    "background = Image.new('RGBA', img.size, (0, 0, 0))\n",
    "\n",
    "alpha_composite = Image.alpha_composite(background, img)\n",
    "alpha_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee5e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nft_id = fn.new_nft_id()\n",
    "quality_val = 100\n",
    "now = fn.get_time()\n",
    "filepath = diffvg_images_dir.joinpath(f'{nft_id}.jpeg')\n",
    "alpha_composite.convert('RGB').save(filepath, quality=quality_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26e52a9",
   "metadata": {},
   "source": [
    "# flow beam graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eae8f6d",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "class GraphGram(object):\n",
    "    \n",
    "    def __init__(self, graph, xoff=0, yoff=0, scale=1, layout_method='kamada_kawai_layout'):\n",
    "        self.graph = graph\n",
    "        self._nodes = None\n",
    "        self.xoff = xoff\n",
    "        self.yoff = yoff\n",
    "        self.scale = scale\n",
    "        self.layout_method = layout_method\n",
    "    \n",
    "    @property\n",
    "    def center(self):\n",
    "        return np.array((self.xoff, self.yoff))\n",
    "    \n",
    "    @property\n",
    "    def edges(self):\n",
    "        return list(self.graph.edges)\n",
    "    \n",
    "    @property\n",
    "    def layout_function(self):\n",
    "        try:\n",
    "            f = getattr(nx.layout, self.layout_method)\n",
    "        except AttributeError:\n",
    "            layout_functions = [a for a in dir(nx.layout) if 'layout' in a]\n",
    "            error_string = f'''{self.layout_method} not found in networkx.layout module; \n",
    "\n",
    "choose from {layout_functions}\n",
    "            '''\n",
    "            print(error_string)\n",
    "        return f\n",
    "    \n",
    "    @functools.lru_cache\n",
    "    def get_layout(self, *args, **kwargs):\n",
    "        self._nodes = self.layout_function(\n",
    "            self.graph,\n",
    "            scale=self.scale,\n",
    "            center=self.center,\n",
    "            *args, **kwargs)\n",
    "    \n",
    "    @property\n",
    "    def nodes(self):\n",
    "        if self._nodes is None:\n",
    "            self.get_layout()\n",
    "        return self._nodes\n",
    "    \n",
    "    @property\n",
    "    def node_pts(self):\n",
    "        return {k:Point(xy) for k, xy in self.nodes.items()}\n",
    "    \n",
    "    @property\n",
    "    def pts(self):\n",
    "        return MultiPoint([p for p in self.node_pts.values()])\n",
    "    \n",
    "    @property\n",
    "    def lines(self):\n",
    "        lines = []\n",
    "        for n0,n1 in self.edges:\n",
    "            p0 = self.node_pts[n0]\n",
    "            p1 = self.node_pts[n1]\n",
    "            lines.append(LineString([p0, p1]))\n",
    "        return MultiLineString(lines)    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f657e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diffvg_images_dir = Path('/home/naka/art/diffvg_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68e8822",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1600\n",
    "height = 1600\n",
    "drawbox = box(0, 0, width, height)\n",
    "db = gp.Shape(drawbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675834f5",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# make page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587c6036",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "DEGREE = 32\n",
    "SCALE = 200\n",
    "(xbins, ybins), (xs, ys) = gp.overlay_grid(drawbox, xstep=400, ystep=400, flatmesh=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9bf6f7",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "p_gen = lambda x: np.interp(x, [xs.min(), xs.max()], [0., 0.5] )\n",
    "_p_gen = gp.make_callable(p_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009f1f00",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "k_gen = 2\n",
    "_k_gen = gp.make_callable(k_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e495dcf9",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'x':xs,\n",
    "    'y':ys,\n",
    "    'k':_k_gen(xs),\n",
    "    'p':_p_gen(xs)\n",
    "})\n",
    "df['k'] = df['k'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123dd92b",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "new_rows = []\n",
    "for i, row in df.iterrows():\n",
    "    k = row['k'].astype(int)\n",
    "    G = nx.connected_watts_strogatz_graph(n=DEGREE, k=k, p=row['p'])\n",
    "    gg = GraphGram(graph=G, layout_method='spring_layout',\n",
    "                   xoff=row['x'], yoff=row['y'], scale=SCALE)\n",
    "    \n",
    "    bezs = []\n",
    "    for ls in gg.lines:\n",
    "        bez = gp.LineString_to_jittered_bezier(\n",
    "            ls, xstd=0., ystd=0., normalized=True, n_eval_points=4)\n",
    "        bezs.append(bez)\n",
    "    bezs = gp.merge_LineStrings(bezs)\n",
    "    new_row = row.to_dict()\n",
    "    new_row['geometry'] = bezs\n",
    "    new_rows.append(new_row)\n",
    "    \n",
    "gdf = geopandas.GeoDataFrame(new_rows)\n",
    "layers = []\n",
    "layers.append(gp.merge_LineStrings(gdf.geometry))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29286e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b349cd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "buffer_gen = stats.uniform(loc=18, scale=20).rvs\n",
    "d_buffer_gen = functools.partial(np.random.uniform, low=-0.8, high=-1.)\n",
    "angles_gen = stats.uniform(loc=0, scale=360).rvs\n",
    "angles_gen = gp.make_callable(80)\n",
    "d_translate_factor_gen = stats.uniform(loc=0.5, scale=0.8).rvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183b67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "fills = []\n",
    "all_polys = Polygon()\n",
    "for i, row in gdf.iterrows():\n",
    "    p = row.geometry.buffer(0.5, cap_style=2, join_style=2, resolution=8)\n",
    "    p = p.buffer(buffer_gen(), cap_style=2, join_style=2)\n",
    "    \n",
    "    stp = gp.ScaleTransPrms(d_buffer=d_buffer_gen(),angles=angles_gen(),d_translate_factor=d_translate_factor_gen(), n_iters=300)\n",
    "    stp.d_buffers += np.random.uniform(-0.15, 0.15, size=stp.d_buffers.shape)\n",
    "    P = gp.Poly(p)\n",
    "    P.fill_scale_trans(**stp.prms)\n",
    "    \n",
    "    visible_area = p.difference(all_polys)\n",
    "    visible_fill = P.fill.intersection(visible_area.buffer(1e-6))\n",
    "        \n",
    "    \n",
    "    fills.append(visible_fill)\n",
    "    all_polys = so.unary_union([all_polys, p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d942edc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_polys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7deb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "fills = [f for f in fills if f.length > 0]\n",
    "all_fills = gp.merge_LineStrings(fills)\n",
    "all_fills = gp.make_like(all_fills, db.p.buffer(-20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99cab2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lts = []\n",
    "for ls in all_fills:\n",
    "    for ii in range(len(ls.coords)-1):\n",
    "        sub_ls = LineString(ls.coords[ii:ii+2])\n",
    "        lt = LineTensor(sub_ls)\n",
    "        lts.append(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5eee11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "canvas_width, canvas_height = width, height\n",
    "num_control_points = torch.tensor([0])\n",
    "shapes = []\n",
    "shape_groups = []\n",
    "for ii, lt in enumerate(lts):\n",
    "    path = dg.Path(num_control_points = num_control_points,\n",
    "                         points = lt.tensor,\n",
    "                         is_closed = False,\n",
    "                         stroke_width = torch.tensor(0.2))\n",
    "    shapes.append(path)\n",
    "    path_group = dg.ShapeGroup(\n",
    "        shape_ids = torch.tensor([ii]),\n",
    "        fill_color = torch.tensor([0.0, 0.0, 0.0, 0.0]),\n",
    "        stroke_color = torch.tensor([1., 1., 1., 0.8]))\n",
    "    shape_groups.append(path_group)\n",
    "\n",
    "\n",
    "scene_args = dg.RenderFunction.serialize_scene(\\\n",
    "    canvas_width, canvas_height, shapes, shape_groups)\n",
    "render = dg.RenderFunction.apply\n",
    "img = render(canvas_width, # width\n",
    "             canvas_height, # height\n",
    "             4,   # num_samples_x\n",
    "             4,   # num_samples_y\n",
    "             0,   # seed\n",
    "             None, # background_image\n",
    "             *scene_args)\n",
    "img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "\n",
    "background = Image.new('RGBA', img.size, (0, 0, 0))\n",
    "\n",
    "alpha_composite = Image.alpha_composite(background, img)\n",
    "alpha_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b468617",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027641df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diffvg_images_dir = Path('/home/naka/art/diffvg_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bd434e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nft_id = fn.new_nft_id()\n",
    "quality_val = 100\n",
    "now = fn.get_time()\n",
    "filepath = diffvg_images_dir.joinpath(f'{nft_id}.jpeg')\n",
    "alpha_composite.convert('RGB').save(filepath, quality=quality_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3e47d4",
   "metadata": {},
   "source": [
    "# bez circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ff1cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1600\n",
    "height = 1600\n",
    "drawbox = box(0, 0, width, height)\n",
    "db = gp.Shape(drawbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f14f0df2-0736-45bc-a338-1b7c1a393202",
   "metadata": {},
   "outputs": [],
   "source": [
    "bps = gp.circle_pack_within_poly(drawbox, rads=[400,200, 100, 55,35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec73d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "bps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a8adc1-4c4f-4ff3-9d28-9cada5021f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "bps2 = gp.circle_pack_within_poly(drawbox, rads=[400,200, 100, 55,35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f738ec8d-b299-435c-b1a1-c9bae1f91b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "bps = bps.difference(bps2.boundary.buffer(1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa239e99-2246-40dd-ba89-c43295b97b40",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "n_layers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf29ecd2-96df-4b7c-8542-b28a01edf36f",
   "metadata": {
    "heading_collapsed": "false"
   },
   "outputs": [],
   "source": [
    "layers = []\n",
    "for ii in range(n_layers):\n",
    "    fills = []\n",
    "    for p in bps:\n",
    "        xjitter_func = 0\n",
    "        yjitter_func = stats.norm(loc=0, scale=np.random.uniform(3, 8.5)).rvs\n",
    "        dist_from_center = p.centroid.distance(bps.centroid)\n",
    "        a = np.interp(dist_from_center, [0, 800], [0, 720])\n",
    "        bhf = gp.BezierHatchFill(\n",
    "            spacing=np.random.uniform(0.8, 1.2),\n",
    "            degrees=a,\n",
    "            poly_to_fill=p, \n",
    "            xjitter_func=xjitter_func, \n",
    "            yjitter_func=yjitter_func,\n",
    "            fill_inscribe_buffer=1.4,\n",
    "            n_nodes_per_line=15,\n",
    "            n_eval_points=40,\n",
    "        )\n",
    "        fills.append(bhf.p)\n",
    "\n",
    "    fills = [f for f in fills if f.length > 0]\n",
    "    layer = gp.merge_LineStrings(fills)\n",
    "    layers.append(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c85b050",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff89fd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlayers = []\n",
    "for layer in tqdm(layers):\n",
    "    mlayers.append(layer.buffer(0.001).buffer(-0.001).boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d4f89f-36f0-40a7-870a-daa9fd98c1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlayers = [gp.merge_LineStrings([l for l in layer if l.length > 0.2]) for layer in mlayers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a15aecc-9721-4567-a626-2ab004281625",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot([np.log10(l.length) for l in mlayers[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb74dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lss = gp.merge_LineStrings(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c44f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "lts = []\n",
    "for ls in lss:\n",
    "    for ii in range(len(ls.coords)-1):\n",
    "        sub_ls = LineString(ls.coords[ii:ii+2])\n",
    "        lt = LineTensor(sub_ls)\n",
    "        lts.append(lt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18453cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5429fcb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "canvas_width, canvas_height = width, height\n",
    "num_control_points = torch.tensor([0])\n",
    "shapes = []\n",
    "shape_groups = []\n",
    "for ii, lt in enumerate(lts):\n",
    "    path = dg.Path(num_control_points = num_control_points,\n",
    "                         points = lt.tensor,\n",
    "                         is_closed = False,\n",
    "                         stroke_width = torch.tensor(0.1))\n",
    "    shapes.append(path)\n",
    "    path_group = dg.ShapeGroup(\n",
    "        shape_ids = torch.tensor([ii]),\n",
    "        fill_color = torch.tensor([0.0, 0.0, 0.0, 0.0]),\n",
    "        stroke_color = torch.tensor([1., 1., 1., 0.8]))\n",
    "    shape_groups.append(path_group)\n",
    "\n",
    "\n",
    "scene_args = dg.RenderFunction.serialize_scene(\\\n",
    "    canvas_width, canvas_height, shapes, shape_groups)\n",
    "render = dg.RenderFunction.apply\n",
    "img = render(canvas_width, # width\n",
    "             canvas_height, # height\n",
    "             4,   # num_samples_x\n",
    "             4,   # num_samples_y\n",
    "             0,   # seed\n",
    "             None, # background_image\n",
    "             *scene_args)\n",
    "img = finalize_image(img.cpu(), as_Image=True)\n",
    "\n",
    "\n",
    "background = Image.new('RGBA', img.size, (0, 0, 0))\n",
    "\n",
    "alpha_composite = Image.alpha_composite(background, img)\n",
    "alpha_composite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768fcf97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c3afb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "diffvg_images_dir = Path('/home/naka/art/diffvg_images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7086865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nft_id = fn.new_nft_id()\n",
    "quality_val = 100\n",
    "now = fn.get_time()\n",
    "filepath = diffvg_images_dir.joinpath(f'{nft_id}.jpeg')\n",
    "alpha_composite.convert('RGB').save(filepath, quality=quality_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa7ff38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8dd23eb8a106e10a9d6673bd6cb60486dc3129d9782f6ed87a7bc18aa7582fa4"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('genpen': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
